{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis of Stack Overflow Survey Data\n",
    "\n",
    "#### Broadly speaking, we are interested in answering the following question: Who are the respondents?\n",
    "\n",
    "In particular, we will look at the following information about respondents:\n",
    "* Country of residence\n",
    "* Gender\n",
    "* Age\n",
    "* Preferred current technology\n",
    "* Technology they are excited about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pprint\n",
    "import column_rename_dicts as crd\n",
    "%matplotlib inline\n",
    "pd.options.display.max_seq_items = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex patterns needed in data cleaning\n",
    "date_pattern = r\"^([1-9]|1[012])[- /.]([1-9]|[12][0-9]|3[01])[- /.](19|20)\\d\\d$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "df_2017 = pd.read_csv('./so-survey-2017/survey_results_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                       DeveloperType WebDeveloperType  \\\n0                                                NaN              NaN   \n1                                                NaN              NaN   \n2                                              Other              NaN   \n3                                                NaN              NaN   \n4  Mobile developer; Graphics programming; Deskto...              NaN   \n\n  MobileDeveloperType NonDeveloperType  \n0                 NaN              NaN  \n1                 NaN              NaN  \n2                 NaN              NaN  \n3                 NaN   Data scientist  \n4                 NaN              NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DeveloperType</th>\n      <th>WebDeveloperType</th>\n      <th>MobileDeveloperType</th>\n      <th>NonDeveloperType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Other</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Data scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mobile developer; Graphics programming; Deskto...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df_2017[['DeveloperType','WebDeveloperType','MobileDeveloperType','NonDeveloperType']].head()\n",
    "# pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CompanyType\nGovernment agency or public school/university                             2451\nI don't know                                                              3233\nI prefer not to answer                                                    1816\nNon-profit/non-governmental organization or private school/university     1225\nPre-series A startup                                                      1288\nPrivately-held limited company, not in startup mode                      16709\nPublicly-traded corporation                                               5871\nSole proprietorship or partnership, not in startup mode                   2831\nSomething else                                                             342\nState-owned company                                                        670\nVenture-funded startup                                                    2387\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df_2017.groupby(['CompanyType']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few rows of the 2013 and 2014 data indicate that there are date values in the following variables that do not make sense, given the expected variable type:\n",
    "* 'YearsProgram'\n",
    "* 'CompanySize'\n",
    "* 'NumDevsAtCompany'\n",
    "* 'SizeOfTeam'\n",
    "\n",
    "The fact that they are all 2013 dates suggests that they may be some sort of date stamp in lieu of a non-response. Since it is not clear what they ought to be, we will recode them as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_null_not_null_as_0_1(df, cols_not_to_recode):\n",
    "    '''\n",
    "    This function will split the data frame into columns that can easily be\n",
    "    recoded as 0/1, and those that cannot. More specifically, if a column\n",
    "    has a single non-NaN string value, and the relevant information is already contained\n",
    "    in the column name, then it will convert that column to a 0/1 dummy\n",
    "    '''\n",
    "    \n",
    "    # Split the dataframe into columns that will be operated on, and those that won't\n",
    "    df_recode = df.drop(columns = cols_not_to_recode)\n",
    "    df = df[cols_not_to_recode]\n",
    "    df_recode = df_recode.notnull().astype('int')\n",
    "    df = pd.concat([df, df_recode], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Rows in 2017 data: 51392\nNumber of Columns in 2017 data: 154\nNumber of Columns in 2017 data with no missing values: 7\nNumber of Columns in 2017 data with > 75% missing values: 14\nNumber of Columns in 2017 data with all missing values: 0\nColumns in 2017 data with no missing values: {'Country', 'ProgramHobby', 'Respondent', 'FormalEducation', 'University', 'Professional', 'EmploymentStatus'}\nColumns in 2017 data with > 75% missing values: {'ExCoderBelonged', 'ExCoderWillNotCode', 'ExCoder10Years', 'ExpectedSalary', 'NonDeveloperType', 'ExCoderBalance', 'TimeAfterBootcamp', 'YearsCodedJobPast', 'ExCoderNotForMe', 'ExCoderSkills', 'ExCoderReturn', 'MobileDeveloperType', 'ExCoderActive', 'WebDeveloperType'}\n"
    }
   ],
   "source": [
    "df_missingness_stats(df_2017, '2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Professional developer                                  36131\nStudent                                                  8224\nProfessional non-developer who sometimes writes code     5140\nUsed to be a professional developer                       983\nNone of these                                             914\nName: Professional, dtype: int64"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df_2017['Professional'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Yes, I program as a hobby                    24801\nYes, both                                    13756\nNo                                            9787\nYes, I contribute to open source projects     3048\nName: ProgramHobby, dtype: int64"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "df_2017['ProgramHobby'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "No                     37543\nYes, full-time          9369\nYes, part-time          3352\nI prefer not to say     1128\nName: University, dtype: int64"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "df_2017['University'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_missingness_stats(df, year):\n",
    "    df.name = year + ' data'\n",
    "    print('Number of Rows in {}: {}'.format(df.name, df.shape[0]))\n",
    "    print('Number of Columns in {}: {}'.format(df.name, df.shape[1]))\n",
    "    print('Number of Columns in {} with no missing values: {}'.format(df.name, len(set(df.columns[~df.isnull().any()]))))\n",
    "    print('Number of Columns in {} with > 75% missing values: {}'.format(df.name, \n",
    "                                                                         len(set(df.columns[df.isnull().sum()/len(df) > .75]))))\n",
    "    print('Number of Columns in {} with all missing values: {}'.format(df.name, \n",
    "                                                                         len(set(df.columns[df.isnull().sum()/len(df) == 1]))))\n",
    "    print('Columns in {} with no missing values: {}'.format(df.name, \n",
    "                                                            set(df.columns[~df.isnull().any()])))\n",
    "    print('Columns in {} with > 75% missing values: {}'.format(df.name, \n",
    "                                                               set(df.columns[df.isnull().sum()/len(df) > .75])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_df(df, cols_to_dummy, dummy_na=True):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    for col in cols_to_dummy:\n",
    "        try:\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], \n",
    "                                                                 prefix=col, \n",
    "                                                                 prefix_sep='_', \n",
    "                                                                 drop_first=True,\n",
    "                                                                 dummy_na=dummy_na\n",
    "                                                                )], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating labelEncoder\n",
    "def process_y_var_split_data(df, yvar):\n",
    "    df[yvar] = df[yvar].str.replace('<', 'less than ')\n",
    "    df[yvar] = df[yvar].str.replace('>', 'greater than ')\n",
    "    df[yvar] = df[yvar].astype('str')\n",
    "    df = df[df[yvar]!='nan']\n",
    "    \n",
    "    print(df[yvar].value_counts())\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    X = df.drop(columns=[yvar])\n",
    "    y = le.fit_transform(df[yvar])\n",
    "    \n",
    "    return X, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2013, y_2013 = process_y_var_split_data(df_2013, 'TotalCompensation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student / Unemployed     1147\n",
      "Rather not say           1130\n",
      "less than $20,000         970\n",
      "$40,000 - $60,000         794\n",
      "$20,000 - $40,000         746\n",
      "$60,000 - $80,000         697\n",
      "$80,000 - $100,000        587\n",
      "$100,000 - $120,000       386\n",
      "greater than $140,000     244\n",
      "$120,000 - $140,000       199\n",
      "Name: TotalCompensation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_2014, y_2014 = process_y_var_split_data(df_2014, 'TotalCompensation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less than $20,000      4000\n",
      "$20,000 - $40,000      2732\n",
      "Rather not say         2628\n",
      "$40,000 - $60,000      2429\n",
      "$60,000 - $80,000      2007\n",
      "Unemployed             1996\n",
      "$80,000 - $100,000     1394\n",
      "$100,000 - $120,000     991\n",
      "$120,000 - $140,000     562\n",
      "More than $160,000      462\n",
      "$140,000 - $160,000     280\n",
      "Name: Compensation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_2015, y_2015 = process_y_var_split_data(df_2015, 'Compensation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.14353163361661944\n",
      "Logistic Regression Accuracy: 0.32483474976392823\n",
      "Random Forest Accuracy: 0.2554296506137866\n",
      "AdaBoost Accuracy: 0.279508970727101\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and test set\n",
    "def compare_classifiers(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42) # 70% training and 30% test\n",
    "\n",
    "\n",
    "    #Create a Gaussian Classifier\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "    # Logistic Regression Classifier\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_lr = logreg.predict(X_test)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    # Adaboost Classifier\n",
    "    ada = AdaBoostClassifier()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "    print(\"GNB Accuracy:\",metrics.accuracy_score(y_test, y_pred_gnb))\n",
    "\n",
    "    print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, y_pred_lr))\n",
    "\n",
    "    print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "    print(\"AdaBoost Accuracy:\",metrics.accuracy_score(y_test, y_pred_ada))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "def compare_classifiers(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42) # 70% training and 30% test\n",
    "\n",
    "    #Create a Gaussian Classifier\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_gnb = gnb.predict(X_test)\n",
    "\n",
    "    # Logistic Regression Classifier\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_lr = logreg.predict(X_test)\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "    # Adaboost Classifier\n",
    "    ada = AdaBoostClassifier()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    ada.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred_ada = ada.predict(X_test)\n",
    "\n",
    "    print(\"GNB Accuracy:\",metrics.accuracy_score(y_test, y_pred_gnb))\n",
    "\n",
    "    print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, y_pred_lr))\n",
    "\n",
    "    print(\"Random Forest Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "    print(\"AdaBoost Accuracy:\",metrics.accuracy_score(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.1067632850241546\n",
      "Logistic Regression Accuracy: 0.39806763285024155\n",
      "Random Forest Accuracy: 0.3565217391304348\n",
      "AdaBoost Accuracy: 0.3782608695652174\n"
     ]
    }
   ],
   "source": [
    "compare_classifiers(X_2014, y_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB Accuracy: 0.03866552609067579\n",
      "Logistic Regression Accuracy: 0.38751069289991447\n",
      "Random Forest Accuracy: 0.28160821214713433\n",
      "AdaBoost Accuracy: 0.3286569717707442\n"
     ]
    }
   ],
   "source": [
    "compare_classifiers(X_2015, y_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(crd.column_name_map_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(list(df_2014.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_counts(df, col, plot_title):\n",
    "    status_vals = df[col].value_counts() \n",
    "    print(status_vals)\n",
    "    # The below is a bar chart of the proportion of observations in each category of df[col]\n",
    "    (status_vals/df.shape[0]).plot(kind=\"bar\");\n",
    "    plt.title(\"What kind of developer are you?\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description(column_name, schema=schema):\n",
    "    '''\n",
    "    INPUT - schema - pandas dataframe with the schema of the developers survey\n",
    "            column_name - string - the name of the column you would like to know about\n",
    "    OUTPUT - \n",
    "            desc - string - the description of the column\n",
    "    '''\n",
    "    desc = schema['Question'][schema['Column']==column_name].values[0]\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_vals = [\"Take online courses\", \"Buy books and work through the exercises\", \n",
    "                 \"None of these\", \"Part-time/evening courses\", \"Return to college\",\n",
    "                 \"Contribute to open source\", \"Conferences/meet-ups\", \"Bootcamp\",\n",
    "                 \"Get a job as a QA tester\", \"Participate in online coding competitions\",\n",
    "                 \"Master's degree\", \"Participate in hackathons\", \"Other\"]\n",
    "\n",
    "def clean_and_plot(df, title='Method of Educating Suggested', plot=True):\n",
    "    '''\n",
    "    INPUT \n",
    "        df - a dataframe holding the CousinEducation column\n",
    "        title - string the title of your plot\n",
    "        axis - axis object\n",
    "        plot - bool providing whether or not you want a plot back\n",
    "        \n",
    "    OUTPUT\n",
    "        study_df - a dataframe with the count of how many individuals\n",
    "        Displays a plot of pretty things related to the CousinEducation column.\n",
    "    '''\n",
    "    study = df['CousinEducation'].value_counts().reset_index()\n",
    "    study.rename(columns={'index': 'method', 'CousinEducation': 'count'}, inplace=True)\n",
    "    study_df = t.total_count(study, 'method', 'count', possible_vals)\n",
    "\n",
    "    study_df.set_index('method', inplace=True)\n",
    "    if plot:\n",
    "        (study_df/study_df.sum()).plot(kind='bar', legend=None);\n",
    "        plt.title(title);\n",
    "        plt.show()\n",
    "    props_study_df = study_df/study_df.sum()\n",
    "    return props_study_df\n",
    "    \n",
    "props_df = clean_and_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitc38d59e534f34b659c3486983a929f38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}